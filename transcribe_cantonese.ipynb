{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b77306",
   "metadata": {},
   "source": [
    "# ðŸŽ™ï¸ Cantonese Voice Transcription - One-Click Setup\n",
    "\n",
    "**Super simple - just 2 steps:**\n",
    "\n",
    "1. **Run the cell below** â¬‡ï¸ (takes 2-3 minutes to prepare)\n",
    "2. **Upload your audio file** when prompted\n",
    "3. **That's it!** Transcript auto-downloads when done\n",
    "\n",
    "Supported formats: MP3, WAV, M4A, FLAC, OGG\n",
    "\n",
    "ðŸ’¡ **Tip:** Go to Runtime â†’ Change runtime type â†’ GPU (optional, makes it faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541b6a11",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "ONE-STEP CANTONESE TRANSCRIPTION\n",
    "Setup + Upload + Transcribe + Download (automatic)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ™ï¸  INSTALLING & SETTING UP WHISPER (ONE TIME)\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Step 1: Install dependencies\n",
    "print(\"ðŸ“¦ Installing dependencies...\")\n",
    "import subprocess\n",
    "subprocess.run(['pip', 'install', '-q', 'openai-whisper'], check=True)\n",
    "subprocess.run(['apt-get', '-qq', 'install', '-y', 'ffmpeg'], check=True)\n",
    "print(\"âœ“ Dependencies installed\\n\")\n",
    "\n",
    "# Step 2: Import libraries\n",
    "print(\"ðŸ“š Importing libraries...\")\n",
    "import whisper\n",
    "import os\n",
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "import torch\n",
    "print(\"âœ“ Libraries ready\\n\")\n",
    "\n",
    "# Step 3: Load model\n",
    "print(\"ðŸ¤– Loading Whisper Large model...\")\n",
    "print(\"   (This takes ~1-2 minutes first time)\\n\")\n",
    "model = whisper.load_model(\"large\")\n",
    "print(\"âœ“ Model loaded\\n\")\n",
    "\n",
    "# Step 4: Upload audio\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“¤ UPLOAD YOUR AUDIO FILE\")\n",
    "print(\"=\"*70)\n",
    "print(\"Click 'Choose Files' button and select your audio file\")\n",
    "print(\"Supported: MP3, WAV, M4A, FLAC, OGG\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "if not uploaded:\n",
    "    print(\"âš ï¸  No files uploaded. Please try again.\")\n",
    "else:\n",
    "    print(f\"\\nâœ“ Uploaded: {list(uploaded.keys())}\\n\")\n",
    "    \n",
    "    # Step 5: Transcribe\n",
    "    print(\"=\"*70)\n",
    "    print(\"ðŸŽ™ï¸  TRANSCRIBING TO CANTONESE (wait 2-5 minutes)\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    def format_timestamp(seconds):\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n",
    "    \n",
    "    for filename in uploaded.keys():\n",
    "        print(f\"\\nðŸ“ Processing: {filename}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Transcribe\n",
    "        result = model.transcribe(\n",
    "            filename,\n",
    "            language='zh',\n",
    "            task='transcribe',\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Create transcript file\n",
    "        transcript_path = Path(filename).stem + '_transcript.txt'\n",
    "        \n",
    "        with open(transcript_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"Transcript: {filename}\\n\")\n",
    "            f.write(f\"Language: Cantonese\\n\")\n",
    "            f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "            f.write(result['text'].strip())\n",
    "            f.write(\"\\n\\n\" + \"=\" * 70 + \"\\n\")\n",
    "            f.write(\"Detailed segments:\\n\\n\")\n",
    "            \n",
    "            for segment in result['segments']:\n",
    "                start = format_timestamp(segment['start'])\n",
    "                end = format_timestamp(segment['end'])\n",
    "                text = segment['text'].strip()\n",
    "                f.write(f\"[{start} â†’ {end}] {text}\\n\")\n",
    "        \n",
    "        print(f\"âœ“ Transcript created: {transcript_path}\\n\")\n",
    "        \n",
    "        # Show preview\n",
    "        print(\"ðŸ“‹ Preview:\")\n",
    "        print(\"-\" * 70)\n",
    "        preview = result['text'][:300]\n",
    "        print(preview)\n",
    "        if len(result['text']) > 300:\n",
    "            print(\"...(more)\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Step 6: Auto-download\n",
    "        print(f\"\\nðŸ“¥ Downloading transcript...\")\n",
    "        files.download(transcript_path)\n",
    "        print(f\"âœ“ Downloaded: {transcript_path}\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ ALL DONE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"Your transcript is downloaded to ~/Downloads/\\n\")\n",
    "print(\"Next step: Run this in terminal to organize:\")\n",
    "print(\"   python3 scripts/trigger_colab.py --organize\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead82064",
   "metadata": {},
   "source": [
    "## âœ¨ That's it!\n",
    "\n",
    "Your transcript is ready and automatically downloaded.\n",
    "\n",
    "**Back in terminal, run:**\n",
    "```\n",
    "python3 scripts/trigger_colab.py --organize\n",
    "```\n",
    "\n",
    "This moves your transcript to the `project/transcripts/` folder. Done! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
